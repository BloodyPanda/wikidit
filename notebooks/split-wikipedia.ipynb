{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwxml\n",
    "import bz2\n",
    "import sqlalchemy_utils\n",
    "from collections import Counter\n",
    "import re\n",
    "import mwparserfromhell as mwparser\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/dumps.wikipedia.org/enwiki/20180901/enwiki-20180901-pages-articles.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revision_to_dict(rev):\n",
    "    \"\"\"Convert a Revision to a dict object\"\"\"\n",
    "    rev = rev.to_json()\n",
    "    rev['rev_id'] = rev['id']\n",
    "    del rev['id']\n",
    "    for k in (\"id\", \"title\", \"namespace\", 'redirect'):\n",
    "        if k != \"restrictions\":\n",
    "            try:\n",
    "                rev[f\"page_{k}\"] = rev[k]\n",
    "            except KeyError:\n",
    "                rev[f\"page_{k}\"] = None\n",
    "        else:\n",
    "            try:\n",
    "                rev[f\"page_restrictions\"] = \" \".join(str(x) for x in rev[k])\n",
    "            except KeyError:\n",
    "                rev[f\"page_restrictions\"] = None\n",
    "    del rev[\"page\"]\n",
    "    for k, v in rev[\"deleted\"].items():\n",
    "        rev[f\"deleted_{k}\"] = v\n",
    "    del rev[\"deleted\"]\n",
    "    for k in (\"id\", \"text\"):\n",
    "        try:\n",
    "            rev[f\"user_{k}\"] = rev[\"user\"][k]\n",
    "        except KeyError:\n",
    "            rev[f\"user_{k}\"] = None\n",
    "    del rev[\"user\"]\n",
    "    rev['is_revision'] = 'page_redirect' in rev\n",
    "    return rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_revision(revision):\n",
    "    \"\"\"Process the revision by converting to dict, parsing the wikicode, and extracting links.\"\"\"\n",
    "    revision = revision_to_dict(revision)\n",
    "    parsed = mwparser.parse(revision['text'])\n",
    "    revision['parsed_text'] = parsed\n",
    "    templates = Counter(str(x.name).strip() for x in parsed.filter_templates())\n",
    "    templates = [{'rev_id': revision['rev_id'], 'name': k, 'count': v} for k, v in templates.items()]\n",
    "    wikilinks = Counter(str(x.title).strip() for x in parsed.filter_wikilinks())\n",
    "    wikilinks = [{'rev_id': revision['rev_id'], 'name': k, 'count': v,\n",
    "                  'category': bool(re.match(\"^category:\", k, re.I)),\n",
    "                  'file': bool(re.match(\"^(file|image):\", k, re.I))\n",
    "                 } \n",
    "                 for k, v in wikilinks.items()]\n",
    "    return {'revisions': [revision], 'wikilinks': wikilinks, 'templates': templates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revisions(filename, max_pages=None):\n",
    "    \"\"\"Iterate over all revisions\"\"\"\n",
    "    with bz2.open(input_file, \"rt\") as f:\n",
    "        dump = mwxml.Dump.from_file(f)\n",
    "        for page in itertools.islice(dump.pages, max_pages):\n",
    "            for rev in page:\n",
    "                yield rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq(iterable, size):\n",
    "    \"\"\"Split iterable into chunks of size ``size``.\"\"\"\n",
    "    it = iter(iterable)\n",
    "    item = list(itertools.islice(it, size))\n",
    "    while item:\n",
    "        yield item\n",
    "        item = list(itertools.islice(it, size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch the number of pages\n",
    "batchsize = 5000\n",
    "max_pages = None\n",
    "workers = cpu_count() - 1\n",
    "\n",
    "def process_chunk(revisions):\n",
    "    queue = {'revisions': [], 'wikilinks': [], 'templates': []}    \n",
    "    for rev in revisions:\n",
    "        for k, v in process_revision(rev).items():\n",
    "            queue[k].extend(v) \n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inserts = {k: metadata.tables[k].insert() for k in ('revisions', 'wikilinks', 'templates')}\n",
    "pool = Parallel(n_jobs=4, batch_size=1)\n",
    "with engine.connect() as conn:\n",
    "    revisions = split_seq(get_revisions(input_file, max_pages=max_pages), batchsize)\n",
    "    for i, x in enumerate(pool(delayed(process_chunk)(rev) for rev in revisions)):\n",
    "        print(f\"Inserting batch {i}\")\n",
    "        for k, v in x.items():\n",
    "            if len(v):\n",
    "                conn.execute(metadata.tables[k].insert(), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
