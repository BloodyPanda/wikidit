{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This messy notebook trains the XGboost model used in wikidit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import wikidit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import _load_backlog, WP10_LABELS\n",
    "from wikidit.io import read_labeled\n",
    "from wikidit.ordinal import SequentialClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/enwiki-labeling_revisions-w_features/\"\n",
    "revisions = read_labeled(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import xgboost as xgb\n",
    "import dill\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, Binarizer\n",
    "\n",
    "count_cols = ['words',\n",
    "             # infobox as a binary\n",
    "             'backlog_accuracy',\n",
    "             'backlog_content',\n",
    "             'backlog_other',\n",
    "             'backlog_style',\n",
    "             'backlog_links']\n",
    "\n",
    "per_word_cols = [\n",
    "             'headings_per_word',\n",
    "             'sub_headings_per_word',\n",
    "             # links\n",
    "             'images_per_word',\n",
    "             'categories_per_word',\n",
    "             'wikilinks_per_word',\n",
    "             'external_links_per_word',\n",
    "             # templates\n",
    "             'main_templates_per_word',\n",
    "             'cite_templates_per_word',\n",
    "             'ref_per_word'    \n",
    "]\n",
    "\n",
    "binarized_cols = ['coordinates', 'infoboxes']\n",
    "\n",
    "response_col = ['wp10']\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    for c in count_cols:\n",
    "        df[c] = np.sqrt(df[c])\n",
    "    for c in binarized_cols:\n",
    "        df[c] = df[c].astype(bool)\n",
    "    allcols = list(itertools.chain(per_word_cols, count_cols, binarized_cols))\n",
    "    return df.loc[:, allcols]\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (count_cols, FunctionTransformer(func=np.sqrt, validate=False)),\n",
    "    (binarized_cols, Binarizer()),\n",
    "    (per_word_cols, None)\n",
    "])\n",
    "\n",
    "X = revisions\n",
    "y = revisions['wp10'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import (f1_score, roc_auc_score, accuracy_score, \n",
    "                             precision_score, recall_score, log_loss, \n",
    "                             confusion_matrix)\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "  'silent': True,\n",
    "  'booster': 'gbtree',\n",
    "  'objective': 'binary:logistic',\n",
    "  'random_state': 12345,\n",
    "  'learning_rate': 0.1,\n",
    "  'n_estimators': 200,\n",
    "  'min_child_weight': 1,\n",
    "  'gamma': 0,\n",
    "  'subsample': 0.9,\n",
    "  'colsample_bytree': 0.9,\n",
    "  'max_depth': 6\n",
    "}\n",
    "# xgb_param_grid = {\n",
    "#    'min_child_weight': list(range(1, 11)),\n",
    "#    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'max_depth': [2, 3, 4, 5, 6, 7, 8]\n",
    "# }\n",
    "\n",
    "clf = SequentialClassifier(xgb.XGBClassifier(**xgb_params))\n",
    "pipeline = Pipeline([('mapper', mapper), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = clone(pipeline).fit(revisions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/xgboost-sequential.pkl\", \"wb\") as f:\n",
    "    dill.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to check that things are working with live API data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "from wikidit.mw import get_page, Session\n",
    "featurizer = Featurizer()\n",
    "session = Session()\n",
    "page = get_page('Correlation')\n",
    "revision = featurizer.parse_content(page['content'])\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits\n",
    "results = predict_page_edits(featurizer, page['content'], fitted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "predictions = []\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train = revisions.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = revisions.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    cv_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = cv_fit.predict(X_test)\n",
    "    predictions.append(pd.DataFrame({'actual': y_test, 'pred': y_pred}))\n",
    "\n",
    "predictions = pd.concat(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the accuracy, average the number of correct binary classifications each observation, then average over all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009252405625463"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(predictions['actual'].cat.categories)\n",
    "np.mean(1 - np.abs(predictions['actual'].cat.codes - predictions['pred'].cat.codes) / (n_classes - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = predictions.groupby(['actual', 'pred']).aggregate(len).reset_index()\n",
    "confusion = confusion.rename(columns={0: 'n'})\n",
    "confusion['p'] = confusion['n'] / confusion['n'].sum()\n",
    "actual_totals = confusion.groupby(['actual'])['n'].transform('sum')\n",
    "confusion['p_actual'] = confusion['n'] / actual_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table = confusion.pivot(index='actual', columns='pred', values='p_actual').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_table, vmin=0, vmax=1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('confusion-matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree of the Ordinal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphic of the tree of the ordinal model used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\troot [label=\"\"]\n",
      "\tstub [label=\"P(Stub)\" shape=rectangle]\n",
      "\tgtstub [label=\"\"]\n",
      "\tstart [label=\"P(Start)\" shape=rectangle]\n",
      "\tgtstart [label=\"\"]\n",
      "\tc [label=\"P(C)\" shape=rectangle]\n",
      "\tgtc [label=\"\"]\n",
      "\tb [label=\"P(B)\" shape=rectangle]\n",
      "\tgtb [label=\"\"]\n",
      "\tga [label=\"P(GA)\" shape=rectangle]\n",
      "\tfa [label=\"P(FA)\" shape=rectangle]\n",
      "\troot -> stub [label=\"P(Stub)\"]\n",
      "\troot -> gtstub [label=\"P(X > Stub)\"]\n",
      "\tgtstub -> start [label=\"P(Start)\"]\n",
      "\tgtstub -> gtstart [label=\"P(X > Start | X > Stub)\"]\n",
      "\tgtstart -> c [label=\"P(X = C | X > Start)\"]\n",
      "\tgtstart -> gtc [label=\"P(X > C | X > Start)\"]\n",
      "\tgtc -> b [label=\"P(X > Start | X > C)\"]\n",
      "\tgtc -> gtb [label=\"P(X > Start | X > C)\"]\n",
      "\tgtb -> ga [label=\"P(X = GA | X > B)\"]\n",
      "\tgtb -> fa [label=\"P(X = FA | X > B)\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dot = Digraph(format='png')\n",
    "dot.node('root', \"\")\n",
    "dot.node('stub', 'P(Stub)', shape=\"rectangle\")\n",
    "dot.node('gtstub', \"\")\n",
    "dot.node('start', \"P(Start)\", shape=\"rectangle\")\n",
    "dot.node('gtstart', \"\", )\n",
    "dot.node('c', 'P(C)', shape=\"rectangle\")\n",
    "dot.node('gtc', \"\")\n",
    "dot.node('b', 'P(B)', shape=\"rectangle\")\n",
    "dot.node('gtb', \"\")\n",
    "dot.node('ga', 'P(GA)', shape=\"rectangle\")\n",
    "dot.node('fa', 'P(FA)', shape=\"rectangle\")\n",
    "dot.edge(\"root\", \"stub\", label=\"P(Stub)\")\n",
    "dot.edge(\"root\", \"gtstub\", label=\"P(X > Stub)\")\n",
    "dot.edge('gtstub', 'start', label=\"P(Start)\")\n",
    "dot.edge('gtstub', 'gtstart', label=\"P(X > Start | X > Stub)\")\n",
    "dot.edge('gtstart', 'c', label=\"P(X = C | X > Start)\")\n",
    "dot.edge('gtstart', 'gtc', label=\"P(X > C | X > Start)\")\n",
    "dot.edge('gtc', 'b', label=\"P(X > Start | X > C)\")\n",
    "dot.edge('gtc', 'gtb', label=\"P(X > Start | X > C)\")\n",
    "dot.edge('gtb', 'ga', label=\"P(X = GA | X > B)\")\n",
    "dot.edge('gtb', 'fa', label=\"P(X = FA | X > B)\")\n",
    "print(dot.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.gv.png'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render('model.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wp10\n",
       "Stub     5486\n",
       "Start    5476\n",
       "C        5485\n",
       "B        5486\n",
       "GA       5495\n",
       "FA       4996\n",
       "Name: wp10, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions.groupby('wp10')['wp10'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'clf__estimator__min_child_weight': randint(1, 5),\n",
    "    'clf__estimator__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'clf__estimator__subsample': uniform(0.70, 1),\n",
    "    'clf__estimator__colsample_bytree': uniform(0.7, 1),\n",
    "    'clf__estimator__max_depth': randint(2, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "take_nd() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-161e52ac087c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 **rnd_search_pars)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[0;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    183\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: take_nd() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "#X = create_features(revisions)\n",
    "\n",
    "rnd_search_pars = {'n_iter': 2, 'n_jobs': 1, 'cv': 2}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(pipeline, xgb_param_grid, scoring='neg_log_loss',\n",
    "                                random_state=1234,\n",
    "                                **rnd_search_pars)\n",
    "rnd_search.fit(revisions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "prob_pred = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[cat] = {\n",
    "    'f1': f1_score(y_test, y_pred),\n",
    "    'recall_score': recall_score(y_test, y_pred),\n",
    "    'precision_score': precision_score(y_test, y_pred),\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "    'roc_auc_score': roc_auc_score(y_test, y_pred),\n",
    "    'log_loss': log_loss(y_test, prob_pred)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding best parameter values for all models, refit using the entire sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-611-13b10fb945ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_estimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature importance for {cat}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for cat, model in model.named_steps['clf'].named_estimators_.items():\n",
    "    xgb.plot_importance(model)\n",
    "    plt.title(f\"Feature importance for {cat}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.mw import get_page, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 171\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 180\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    100\u001b[0m                                         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                                         auth=auth)\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f5ccea616405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data science\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/insight/wikidit/wikidit/mw.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(session, title)\u001b[0m\n\u001b[1;32m     99\u001b[0m               \u001b[0;34m'redirects'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m               'rvprop': 'ids|content|timestamp', \"rvslots\": \"main\"}\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# There is no such page!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, query_continue, auth, continuation, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m         return self.request('GET', params=params, auth=auth,\n\u001b[1;32m    308\u001b[0m                             \u001b[0mquery_continue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_continue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                             continuation=continuation)\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     def post(self, query_continue=None, upload_file=None, auth=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, params, query_continue, files, auth, continuation)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             return self._request(method, params=normal_params, auth=auth,\n\u001b[0;32m--> 171\u001b[0;31m                                  files=files)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     def continuation(self, method, params=None, query_continue=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "page = get_page(session, \"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "featurizer = Featurizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized = featurizer.featurize(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"../models/xgboost-sequential.pkl\", \"rb\") as f:\n",
    "    MODEL = dill.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Data science\"\n",
    "# session = Session()\n",
    "# page = get_page(session, title)\n",
    "# result = predict_page_edits(featurizer, page['content'], MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import qual_score, make_edits\n",
    "content = page['content']\n",
    "featurizer = Featurizer()\n",
    "model = MODEL\n",
    "revision = featurizer.parse_content(content)\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])\n",
    "# revision = create_features(revision)\n",
    "\n",
    "# probabilities for current class\n",
    "prob = model.predict_proba(revision)\n",
    "best = str(model.predict(revision)[0])\n",
    "score = qual_score(prob)\n",
    "\n",
    "# Calc new probabilities for all types of edits\n",
    "edits = [(nm, description, pd.DataFrame.from_records([x])) \n",
    "         for nm, x, description in make_edits(revision.to_dict('records')[0])]\n",
    "edit_probs = [(nm, description, model.predict_proba(ed)) for nm, description, ed in edits]\n",
    "edit_scores = [(nm, description, qual_score(p)) for nm, description, p in edit_probs]\n",
    "edit_changes = [(n, d, s - score) for n, d, s in edit_scores]\n",
    "top_edits = sorted([x for x in edit_changes if x[2] > 0], key=lambda x: -x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.26, 0.26, 0.37, 0.1 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(prob, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infoboxes',\n",
       "  '<a href=\"https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Infoboxes\">Add an infobox</a>',\n",
       "  0.40727842903825273),\n",
       " ('words', 'Add a sentence (15 words)', 0.023514236413411993)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['top_edits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "headings\n",
      "sub_headings\n",
      "images\n",
      "categories\n",
      "wikilinks\n",
      "external_links\n",
      "citation\n",
      "ref\n",
      "coordinates\n",
      "infoboxes\n",
      "backlog_accuracy\n",
      "backlog_other\n",
      "backlog_style\n",
      "backlog_links\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   words  infoboxes  ref\n",
      "0   1887          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1875          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1872       True   60\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    if w in ('words', 'infoboxes', 'ref'):\n",
    "        print(data.loc[:, ['words', 'infoboxes', 'ref']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.25 0.27 0.38 0.1 ]]\n",
      "[[0.   0.   0.17 0.1  0.56 0.16]]\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_probs:\n",
    "    if w in ('words', 'infoboxs'):\n",
    "        print(np.round(data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32\n",
      "4.7\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_scores:\n",
    "    if w in ('words', 'infoboxes'):\n",
    "        print(np.round(data, 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.29364713400031"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41000000000000014"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.7 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03000000000000025"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.32 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backlog_accuracy</th>\n",
       "      <th>backlog_accuracy_templates</th>\n",
       "      <th>backlog_content</th>\n",
       "      <th>backlog_content_templates</th>\n",
       "      <th>backlog_files</th>\n",
       "      <th>backlog_files_templates</th>\n",
       "      <th>backlog_links</th>\n",
       "      <th>backlog_links_templates</th>\n",
       "      <th>backlog_other</th>\n",
       "      <th>backlog_other_templates</th>\n",
       "      <th>...</th>\n",
       "      <th>ref_per_word</th>\n",
       "      <th>smartlists</th>\n",
       "      <th>smartlists_per_word</th>\n",
       "      <th>sub_headings</th>\n",
       "      <th>sub_headings_per_word</th>\n",
       "      <th>templates</th>\n",
       "      <th>templates_per_word</th>\n",
       "      <th>wikilinks</th>\n",
       "      <th>wikilinks_per_word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>84</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   backlog_accuracy backlog_accuracy_templates  backlog_content  \\\n",
       "0                 0                       None                0   \n",
       "\n",
       "  backlog_content_templates  backlog_files backlog_files_templates  \\\n",
       "0                      None              0                    None   \n",
       "\n",
       "   backlog_links backlog_links_templates  backlog_other  \\\n",
       "0              0                    None              0   \n",
       "\n",
       "  backlog_other_templates  ...    ref_per_word smartlists  \\\n",
       "0                    None  ...        0.032051          0   \n",
       "\n",
       "   smartlists_per_word  sub_headings  sub_headings_per_word  templates  \\\n",
       "0                  0.0             0                    0.0         42   \n",
       "\n",
       "   templates_per_word  wikilinks  wikilinks_per_word  words  \n",
       "0            0.022436         84            0.044872   1872  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import make_edits, add_per_word, add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
