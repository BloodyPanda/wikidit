{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This messy notebook trains the XGboost model used in wikidit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import wikidit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import _load_backlog, WP10_LABELS\n",
    "from wikidit.io import read_labeled\n",
    "from wikidit.ordinal import SequentialClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/enwiki-labeling_revisions-w_features/\"\n",
    "revisions = read_labeled(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import xgboost as xgb\n",
    "import dill\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, Binarizer\n",
    "\n",
    "count_cols = ['words',\n",
    "             # infobox as a binary\n",
    "             'backlog_accuracy',\n",
    "             'backlog_content',\n",
    "             'backlog_other',\n",
    "             'backlog_style',\n",
    "             'backlog_links']\n",
    "\n",
    "per_word_cols = [\n",
    "             'headings_per_word',\n",
    "             'sub_headings_per_word',\n",
    "             # links\n",
    "             'images_per_word',\n",
    "             'categories_per_word',\n",
    "             'wikilinks_per_word',\n",
    "             'external_links_per_word',\n",
    "             # templates\n",
    "             'main_templates_per_word',\n",
    "             'cite_templates_per_word',\n",
    "             'ref_per_word'    \n",
    "]\n",
    "\n",
    "binarized_cols = ['coordinates', 'infoboxes']\n",
    "\n",
    "response_col = ['wp10']\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    for c in count_cols:\n",
    "        df[c] = np.sqrt(df[c])\n",
    "    for c in binarized_cols:\n",
    "        df[c] = df[c].astype(bool)\n",
    "    allcols = list(itertools.chain(per_word_cols, count_cols, binarized_cols))\n",
    "    return df.loc[:, allcols]\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (count_cols, FunctionTransformer(func=np.sqrt, validate=False)),\n",
    "    (binarized_cols, Binarizer()),\n",
    "    (per_word_cols, None)\n",
    "])\n",
    "\n",
    "y = revisions['wp10'].values.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import (f1_score, roc_auc_score, accuracy_score, \n",
    "                             precision_score, recall_score, log_loss, \n",
    "                             confusion_matrix)\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "  'silent': True,\n",
    "  'booster': 'gbtree',\n",
    "  'objective': 'binary:logistic',\n",
    "  'random_state': 12345,\n",
    "  'learning_rate': 0.1,\n",
    "  'n_estimators': 200,\n",
    "  'min_child_weight': 1,\n",
    "  'gamma': 0,\n",
    "  'subsample': 0.9,\n",
    "  'colsample_bytree': 0.9,\n",
    "  'max_depth': 6\n",
    "}\n",
    "# xgb_param_grid = {\n",
    "#    'min_child_weight': list(range(1, 11)),\n",
    "#    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'max_depth': [2, 3, 4, 5, 6, 7, 8]\n",
    "# }\n",
    "\n",
    "clf = SequentialClassifier(xgb.XGBClassifier(**xgb_params))\n",
    "pipeline = Pipeline([('mapper', mapper), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = pipeline.fit(revisions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/xgboost-sequential.pkl\", \"wb\") as f:\n",
    "    dill.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to check that things are working with live API data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "from wikidit.mw import get_page, Session\n",
    "featurizer = Featurizer()\n",
    "session = Session()\n",
    "page = get_page('xgboost')\n",
    "revision = featurizer.parse_content(page['content'])\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits\n",
    "results = predict_page_edits(featurizer, page['content'], fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=12345)\n",
    "predictions = []\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train = revisions.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = revisions.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    # print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    cv_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = cv_fit.predict(X_test)\n",
    "    predictions.append(pd.DataFrame({'actual': y_test, 'pred': y_pred}))\n",
    "\n",
    "predictions = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import WP10_DTYPE, WP10_LABELS\n",
    "import pandas as pd\n",
    "for c in ('actual', 'pred'):\n",
    "    predictions[c] = pd.Categorical.from_codes(predictions[c], WP10_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the accuracy, average the number of correct binary classifications each observation, then average over all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1 - np.mean(np.abs(predictions['actual'].cat.codes - predictions['pred'].cat.codes) / 5), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = predictions.groupby(['actual', 'pred']).aggregate(len).reset_index()\n",
    "confusion = confusion.rename(columns={0: 'n'})\n",
    "confusion['p'] = confusion['n'] / confusion['n'].sum()\n",
    "actual_totals = confusion.groupby(['actual'])['n'].transform('sum')\n",
    "confusion['p_actual'] = confusion['n'] / actual_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table = confusion.pivot(index='actual', columns='pred', values='p_actual').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_table, vmin=0, vmax=1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('confusion-matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree of the Ordinal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphic of the tree of the ordinal model used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\troot [label=\"\"]\n",
      "\tstub [label=\"P(Stub)\" shape=rectangle]\n",
      "\tgtstub [label=\"\"]\n",
      "\tstart [label=\"P(Start)\" shape=rectangle]\n",
      "\tgtstart [label=\"\"]\n",
      "\tc [label=\"P(C)\" shape=rectangle]\n",
      "\tgtc [label=\"\"]\n",
      "\tb [label=\"P(B)\" shape=rectangle]\n",
      "\tgtb [label=\"\"]\n",
      "\tga [label=\"P(GA)\" shape=rectangle]\n",
      "\tfa [label=\"P(FA)\" shape=rectangle]\n",
      "\troot -> stub [label=\"P(Stub)\"]\n",
      "\troot -> gtstub [label=\"P(X > Stub)\"]\n",
      "\tgtstub -> start [label=\"P(Start)\"]\n",
      "\tgtstub -> gtstart [label=\"P(X > Start | X > Stub)\"]\n",
      "\tgtstart -> c [label=\"P(X = C | X > Start)\"]\n",
      "\tgtstart -> gtc [label=\"P(X > C | X > Start)\"]\n",
      "\tgtc -> b [label=\"P(X > Start | X > C)\"]\n",
      "\tgtc -> gtb [label=\"P(X > Start | X > C)\"]\n",
      "\tgtb -> ga [label=\"P(X = GA | X > B)\"]\n",
      "\tgtb -> fa [label=\"P(X = FA | X > B)\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dot = Digraph(format='png')\n",
    "dot.node('root', \"\")\n",
    "dot.node('stub', 'P(Stub)', shape=\"rectangle\")\n",
    "dot.node('gtstub', \"\")\n",
    "dot.node('start', \"P(Start)\", shape=\"rectangle\")\n",
    "dot.node('gtstart', \"\", )\n",
    "dot.node('c', 'P(C)', shape=\"rectangle\")\n",
    "dot.node('gtc', \"\")\n",
    "dot.node('b', 'P(B)', shape=\"rectangle\")\n",
    "dot.node('gtb', \"\")\n",
    "dot.node('ga', 'P(GA)', shape=\"rectangle\")\n",
    "dot.node('fa', 'P(FA)', shape=\"rectangle\")\n",
    "dot.edge(\"root\", \"stub\", label=\"P(Stub)\")\n",
    "dot.edge(\"root\", \"gtstub\", label=\"P(X > Stub)\")\n",
    "dot.edge('gtstub', 'start', label=\"P(Start)\")\n",
    "dot.edge('gtstub', 'gtstart', label=\"P(X > Start | X > Stub)\")\n",
    "dot.edge('gtstart', 'c', label=\"P(X = C | X > Start)\")\n",
    "dot.edge('gtstart', 'gtc', label=\"P(X > C | X > Start)\")\n",
    "dot.edge('gtc', 'b', label=\"P(X > Start | X > C)\")\n",
    "dot.edge('gtc', 'gtb', label=\"P(X > Start | X > C)\")\n",
    "dot.edge('gtb', 'ga', label=\"P(X = GA | X > B)\")\n",
    "dot.edge('gtb', 'fa', label=\"P(X = FA | X > B)\")\n",
    "print(dot.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.gv.png'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render('model.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wp10\n",
       "Stub     5486\n",
       "Start    5476\n",
       "C        5485\n",
       "B        5486\n",
       "GA       5495\n",
       "FA       4996\n",
       "Name: wp10, dtype: int64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions.groupby('wp10')['wp10'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'clf__estimator__min_child_weight': randint(1, 5),\n",
    "    'clf__estimator__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'clf__estimator__subsample': [0.7, 0.8, 0.9, 0.95, 0.99, 1],\n",
    "    'clf__estimator__colsample_bytree': [0.7, 0.8, 0.9, 0.95, 0.99, 1],\n",
    "    'clf__estimator__max_depth': randint(2, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_train, revisions_test, y_train, y_test = train_test_split(revisions, y, test_size=0.8, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6484, 16213]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-361-17265dc6f670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 **rnd_search_pars)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevisions_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 230\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6484, 16213]"
     ]
    }
   ],
   "source": [
    "rnd_search_pars = {'n_iter': 10, 'n_jobs': 5, 'cv': 5}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(pipeline, xgb_param_grid, scoring='neg_log_loss',\n",
    "                                random_state=1234,\n",
    "                                **rnd_search_pars)\n",
    "foo = rnd_search.fit(revisions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = foo.predict(revisions_test)\n",
    "prob_pred = foo.predict_proba(revisions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25940, 16211]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-bf09badf6ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevisions_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m                              % self.best_estimator_)\n\u001b[1;32m    461\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    133\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \"\"\"\n\u001b[1;32m   1763\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 230\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25940, 16211]"
     ]
    }
   ],
   "source": [
    "foo.score(revisions_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequentialClassifier' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-6220662ca268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mclasses_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classes_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mclasses_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequentialClassifier' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "np.abs(y_test - y_pred) / classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding best parameter values for all models, refit using the entire sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-611-13b10fb945ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_estimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature importance for {cat}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for cat, model in model.named_steps['clf'].named_estimators_.items():\n",
    "    xgb.plot_importance(model)\n",
    "    plt.title(f\"Feature importance for {cat}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.mw import get_page, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 171\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 180\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    100\u001b[0m                                         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                                         auth=auth)\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f5ccea616405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data science\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/insight/wikidit/wikidit/mw.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(session, title)\u001b[0m\n\u001b[1;32m     99\u001b[0m               \u001b[0;34m'redirects'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m               'rvprop': 'ids|content|timestamp', \"rvslots\": \"main\"}\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# There is no such page!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, query_continue, auth, continuation, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m         return self.request('GET', params=params, auth=auth,\n\u001b[1;32m    308\u001b[0m                             \u001b[0mquery_continue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_continue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                             continuation=continuation)\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     def post(self, query_continue=None, upload_file=None, auth=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, params, query_continue, files, auth, continuation)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             return self._request(method, params=normal_params, auth=auth,\n\u001b[0;32m--> 171\u001b[0;31m                                  files=files)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     def continuation(self, method, params=None, query_continue=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "page = get_page(session, \"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "featurizer = Featurizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized = featurizer.featurize(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"../models/xgboost-sequential.pkl\", \"rb\") as f:\n",
    "    MODEL = dill.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Data science\"\n",
    "# session = Session()\n",
    "# page = get_page(session, title)\n",
    "# result = predict_page_edits(featurizer, page['content'], MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import qual_score, make_edits\n",
    "content = page['content']\n",
    "featurizer = Featurizer()\n",
    "model = MODEL\n",
    "revision = featurizer.parse_content(content)\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])\n",
    "# revision = create_features(revision)\n",
    "\n",
    "# probabilities for current class\n",
    "prob = model.predict_proba(revision)\n",
    "best = str(model.predict(revision)[0])\n",
    "score = qual_score(prob)\n",
    "\n",
    "# Calc new probabilities for all types of edits\n",
    "edits = [(nm, description, pd.DataFrame.from_records([x])) \n",
    "         for nm, x, description in make_edits(revision.to_dict('records')[0])]\n",
    "edit_probs = [(nm, description, model.predict_proba(ed)) for nm, description, ed in edits]\n",
    "edit_scores = [(nm, description, qual_score(p)) for nm, description, p in edit_probs]\n",
    "edit_changes = [(n, d, s - score) for n, d, s in edit_scores]\n",
    "top_edits = sorted([x for x in edit_changes if x[2] > 0], key=lambda x: -x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.26, 0.26, 0.37, 0.1 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(prob, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infoboxes',\n",
       "  '<a href=\"https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Infoboxes\">Add an infobox</a>',\n",
       "  0.40727842903825273),\n",
       " ('words', 'Add a sentence (15 words)', 0.023514236413411993)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['top_edits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "headings\n",
      "sub_headings\n",
      "images\n",
      "categories\n",
      "wikilinks\n",
      "external_links\n",
      "citation\n",
      "ref\n",
      "coordinates\n",
      "infoboxes\n",
      "backlog_accuracy\n",
      "backlog_other\n",
      "backlog_style\n",
      "backlog_links\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   words  infoboxes  ref\n",
      "0   1887          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1875          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1872       True   60\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    if w in ('words', 'infoboxes', 'ref'):\n",
    "        print(data.loc[:, ['words', 'infoboxes', 'ref']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.25 0.27 0.38 0.1 ]]\n",
      "[[0.   0.   0.17 0.1  0.56 0.16]]\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_probs:\n",
    "    if w in ('words', 'infoboxs'):\n",
    "        print(np.round(data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32\n",
      "4.7\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_scores:\n",
    "    if w in ('words', 'infoboxes'):\n",
    "        print(np.round(data, 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.29364713400031"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41000000000000014"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.7 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03000000000000025"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.32 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backlog_accuracy</th>\n",
       "      <th>backlog_accuracy_templates</th>\n",
       "      <th>backlog_content</th>\n",
       "      <th>backlog_content_templates</th>\n",
       "      <th>backlog_files</th>\n",
       "      <th>backlog_files_templates</th>\n",
       "      <th>backlog_links</th>\n",
       "      <th>backlog_links_templates</th>\n",
       "      <th>backlog_other</th>\n",
       "      <th>backlog_other_templates</th>\n",
       "      <th>...</th>\n",
       "      <th>ref_per_word</th>\n",
       "      <th>smartlists</th>\n",
       "      <th>smartlists_per_word</th>\n",
       "      <th>sub_headings</th>\n",
       "      <th>sub_headings_per_word</th>\n",
       "      <th>templates</th>\n",
       "      <th>templates_per_word</th>\n",
       "      <th>wikilinks</th>\n",
       "      <th>wikilinks_per_word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>84</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   backlog_accuracy backlog_accuracy_templates  backlog_content  \\\n",
       "0                 0                       None                0   \n",
       "\n",
       "  backlog_content_templates  backlog_files backlog_files_templates  \\\n",
       "0                      None              0                    None   \n",
       "\n",
       "   backlog_links backlog_links_templates  backlog_other  \\\n",
       "0              0                    None              0   \n",
       "\n",
       "  backlog_other_templates  ...    ref_per_word smartlists  \\\n",
       "0                    None  ...        0.032051          0   \n",
       "\n",
       "   smartlists_per_word  sub_headings  sub_headings_per_word  templates  \\\n",
       "0                  0.0             0                    0.0         42   \n",
       "\n",
       "   templates_per_word  wikilinks  wikilinks_per_word  words  \n",
       "0            0.022436         84            0.044872   1872  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import make_edits, add_per_word, add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
