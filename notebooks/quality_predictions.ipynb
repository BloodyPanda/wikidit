{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn_pandas import cross_val_score, DataFrameMapper\n",
    "from pandas import Categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mwapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import featurize, load_wp10, OrdinalClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/enwiki.labeling_revisions.w_features.nettrom_30k.csv.gz\"\n",
    "revisions = load_wp10(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "sqrt_cols = ['words',\n",
    "             \n",
    "             'headings',\n",
    "             'sub_headings',\n",
    "             'images',\n",
    "             'categories',\n",
    "             'wikilinks',\n",
    "\n",
    "             'who_templates',\n",
    "             'main_templates',\n",
    "             'cite_templates',\n",
    "             # infobox as a binary\n",
    "             'citation_needed',\n",
    "             'other_templates',\n",
    "\n",
    "             'ref',\n",
    "             'smartlists',\n",
    "             'coordinates']\n",
    "\n",
    "binarized_cols = ['coordinates', 'infoboxes']\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (sqrt_cols, FunctionTransformer(func=np.sqrt)),\n",
    "    (binarized_cols, FunctionTransformer(func=lambda x: x.astype(bool)))\n",
    "])\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.01, \n",
    "                        n_estimators=100, silent=True, \n",
    "                        objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(mapper.fit_transform(revisions))\n",
    "param = {'max_depth':10, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "num_round = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(mapper.fit_transform(revisions), label=revisions['wp10'] > 'Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073379</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.003556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064119</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059570</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.107235</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056486</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.108284</td>\n",
       "      <td>0.002771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.108037</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.108253</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046077</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.044419</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.110165</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.073379         0.001198         0.110258        0.003556\n",
       "1          0.064119         0.001073         0.109394        0.001530\n",
       "2          0.059570         0.001968         0.107235        0.002285\n",
       "3          0.056486         0.001921         0.108284        0.002771\n",
       "4          0.053225         0.001978         0.108037        0.001737\n",
       "5          0.050472         0.001933         0.108253        0.001935\n",
       "6          0.048128         0.001854         0.108870        0.001781\n",
       "7          0.046077         0.001280         0.110196        0.001407\n",
       "8          0.044419         0.001446         0.110196        0.001279\n",
       "9          0.040263         0.003480         0.110165        0.001323"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.cv(param, dtrain, enum_round, nfold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _parallel_fit_estimator(estimator, X, y, cat):\n",
    "    \"\"\"Private function used to fit an estimator to a class within a job.\"\"\"\n",
    "    touse = (y >= cat)\n",
    "    y_transformed = y[touse] > cat\n",
    "    estimator.fit(X[touse, :], y_transformed)\n",
    "    return estimator\n",
    "\n",
    "\n",
    "class OrdinalClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=None, proba_transform=None, left=True):\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.proba_transform = proba_transform\n",
    "        self.left = left\n",
    "\n",
    "    @property\n",
    "    def named_estimators(self):\n",
    "        return Bunch(**dict(self.estimator))\n",
    "\n",
    "    def fit(self, X, y, categories='auto'):\n",
    "        if not (isinstance(y, pd.Series) and hasattr(y, \"cat\")):\n",
    "            raise ValueError(\"y must be pd.Series object with dtype Categorical\")\n",
    "\n",
    "        # this is hard-coded for categorical variables\n",
    "        self.classes_ = y.cat.categories\n",
    "\n",
    "        categories = self.classes_[:-1]\n",
    "    \n",
    "        # order of estimators\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(_parallel_fit_estimator)(clone(self.estimator), X, y, cat)\n",
    "                for cat in categories)\n",
    "\n",
    "        self.named_estimators_ = Bunch(**dict())\n",
    "        for k, e in zip(self.classes_[:-1], self.estimators_):\n",
    "            self.named_estimators_[k] = e\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = np.argmax(self.predict_proba(X), axis=1)\n",
    "        out = pd.Categorical.from_codes(out, categories=self.classes_, ordered=True)\n",
    "        return out\n",
    "\n",
    "    def _collect_log_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        if hasattr(clf, \"predict_log_proba\"):\n",
    "            return [clf.predict_log_proba(X) for clf in self.estimators_]\n",
    "        else:\n",
    "            return [np.log(clf.predict_proba(X)) for clf in self.estimators_]\n",
    "\n",
    "    def _predict_log_proba(self, X):\n",
    "        \"\"\"Predict log class probabilities for X\"\"\"\n",
    "        out = np.empty((X.shape[0], len(self.classes_)))\n",
    "        for i, logp in enumerate(self._collect_log_probas(X)):\n",
    "            if i > 0:\n",
    "                # add log conditional probability\n",
    "                logp += out[:, (i, )]\n",
    "            out[:, i:(i + 2)] = logp\n",
    "        return out\n",
    "\n",
    "    @property\n",
    "    def predict_log_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_log_proba\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.exp(self.predict_log_proba(X))\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.proba_transform:\n",
    "            return self.predict_proba(X)\n",
    "        else:\n",
    "            return self.predict(X)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\" Setting the parameters for the voting classifier\n",
    "        Valid parameter keys can be listed with get_params().\n",
    "        Parameters\n",
    "        ----------\n",
    "        **params : keyword arguments\n",
    "            Specific parameters using e.g. set_params(parameter_name=new_value)\n",
    "            In addition, to setting the parameters of the ``VotingClassifier``,\n",
    "            the individual classifiers of the ``VotingClassifier`` can also be\n",
    "            set or replaced by setting them to None.\n",
    "        Examples\n",
    "        --------\n",
    "        # In this example, the RandomForestClassifier is removed\n",
    "        clf1 = LogisticRegression()\n",
    "        clf2 = RandomForestClassifier()\n",
    "        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)]\n",
    "        eclf.set_params(rf=None)\n",
    "        \"\"\"\n",
    "        super(OrdinalClassifier, self)._set_params('estimator', **params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return super(OrdinalClassifier, self)._get_params('estimator', deep=deep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('clf', OrdinalClassifier(clf))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model on Full Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fitted = pipe.fit(X=revisions.copy(), y=revisions['wp10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "revisions['pred'] = pipe.predict(X = revisions.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>Stub</th>\n",
       "      <th>Start</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>GA</th>\n",
       "      <th>FA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stub</th>\n",
       "      <td>4942</td>\n",
       "      <td>523</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start</th>\n",
       "      <td>1029</td>\n",
       "      <td>3819</td>\n",
       "      <td>502</td>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>164</td>\n",
       "      <td>1765</td>\n",
       "      <td>2835</td>\n",
       "      <td>299</td>\n",
       "      <td>301</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>111</td>\n",
       "      <td>1293</td>\n",
       "      <td>2102</td>\n",
       "      <td>1133</td>\n",
       "      <td>449</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>131</td>\n",
       "      <td>258</td>\n",
       "      <td>1260</td>\n",
       "      <td>212</td>\n",
       "      <td>2294</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FA</th>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>276</td>\n",
       "      <td>236</td>\n",
       "      <td>701</td>\n",
       "      <td>3630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred   Stub  Start     C     B    GA    FA\n",
       "wp10                                      \n",
       "Stub   4942    523    17     3     1     0\n",
       "Start  1029   3819   502    98    25     3\n",
       "C       164   1765  2835   299   301   121\n",
       "B       111   1293  2102  1133   449   398\n",
       "GA      131    258  1260   212  2294  1340\n",
       "FA      114     39   276   236   701  3630"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_ct = pd.crosstab(index=revisions[\"wp10\"], \n",
    "                     columns=revisions[\"pred\"])\n",
    "# rev_ct.index= [\"wp10\", \"pred\"]\n",
    "rev_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stub 0.935449050086\n",
      "Start 0.860473723168\n",
      "C 0.801535899334\n",
      "B 0.882062669627\n",
      "GA 0.90044411547\n",
      "FA 1.0\n"
     ]
    }
   ],
   "source": [
    "for cat in (\"Stub\", \"Start\", \"C\", \"B\", \"GA\", \"FA\"): \n",
    "    print(cat, np.mean((revisions[\"pred\"] <= cat) == (revisions[\"wp10\"] <= cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted.score(X=revisions.copy(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/model.pkl\", \"wb\")  as f:\n",
    "    dill.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _parallel_fit_estimator2(estimator, X, y, cat):\n",
    "    \"\"\"Private function used to fit an estimator to a class within a job.\"\"\"\n",
    "    y_transformed = y > cat\n",
    "    estimator.fit(X, y_transformed)\n",
    "    return estimator\n",
    "\n",
    "\n",
    "class OrdinalClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=None, proba_transform=None, left=True):\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.proba_transform = proba_transform\n",
    "\n",
    "    @property\n",
    "    def named_estimators(self):\n",
    "        return Bunch(**dict(self.estimator))\n",
    "\n",
    "    def fit(self, X, y, categories='auto'):\n",
    "        if not (isinstance(y, pd.Series) and hasattr(y, \"cat\")):\n",
    "            raise ValueError(\"y must be pd.Series object with dtype Categorical\")\n",
    "\n",
    "        # this is hard-coded for categorical variables\n",
    "        self.classes_ = y.cat.categories\n",
    "\n",
    "        categories = self.classes_[1:]\n",
    "    \n",
    "        # order of estimators\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(_parallel_fit_estimator)(clone(self.estimator), X, y, cat)\n",
    "                for cat in categories)\n",
    "\n",
    "        self.named_estimators_ = Bunch(**dict())\n",
    "        for k, e in zip(self.classes_[1:], self.estimators_):\n",
    "            self.named_estimators_[k] = e\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = np.argmax(self.predict_proba(X), axis=1)\n",
    "        out = pd.Categorical.from_codes(out, categories=self.classes_, ordered=True)\n",
    "        return out\n",
    "\n",
    "    def _collect_log_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        if hasattr(clf, \"predict_log_proba\"):\n",
    "            return [clf.predict_log_proba(X) for clf in self.estimators_]\n",
    "        else:\n",
    "            return [np.log(clf.predict_proba(X)) for clf in self.estimators_]\n",
    "\n",
    "    def _predict_log_proba(self, X):\n",
    "        \"\"\"Predict log class probabilities for X\"\"\"\n",
    "        out = np.empty((X.shape[0], len(self.classes_)))\n",
    "        for i, logp in enumerate(self._collect_log_probas(X)):\n",
    "            if i > 0:\n",
    "                # add log conditional probability\n",
    "                logp += out[:, (i, )]\n",
    "            out[:, i:(i + 2)] = logp\n",
    "        return out\n",
    "\n",
    "    @property\n",
    "    def predict_log_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_log_proba\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.exp(self.predict_log_proba(X))\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.proba_transform:\n",
    "            return self.predict_proba(X)\n",
    "        else:\n",
    "            return self.predict(X)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\" Setting the parameters for the voting classifier\n",
    "        Valid parameter keys can be listed with get_params().\n",
    "        Parameters\n",
    "        ----------\n",
    "        **params : keyword arguments\n",
    "            Specific parameters using e.g. set_params(parameter_name=new_value)\n",
    "            In addition, to setting the parameters of the ``VotingClassifier``,\n",
    "            the individual classifiers of the ``VotingClassifier`` can also be\n",
    "            set or replaced by setting them to None.\n",
    "        Examples\n",
    "        --------\n",
    "        # In this example, the RandomForestClassifier is removed\n",
    "        clf1 = LogisticRegression()\n",
    "        clf2 = RandomForestClassifier()\n",
    "        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)]\n",
    "        eclf.set_params(rf=None)\n",
    "        \"\"\"\n",
    "        super(OrdinalClassifier, self)._set_params('estimator', **params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return super(OrdinalClassifier, self)._get_params('estimator', deep=deep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. Cross validate\n",
    "2. Out of sample\n",
    "3. Other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
